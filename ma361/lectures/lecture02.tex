\section{Probability spaces} \label{sec:prob}
\lecture{2024-08-06}{Probability measures and their existence}
\begin{definition*}[probability space] \label{def:prob}
    A \emph{probability space} is a triple $(\Omega, \F, \P)$,
    where $\Omega$ is a non-empty set called the \emph{sample space},
    $\F$ is a $\sigma$-algebra on $\Omega$, and
    $\P$ is a \emph{probability measure} on $\F$.

    A \emph{probability measure} on a $\sigma$-algebra $\F$ is a function
    $\P\colon \F \to [0, 1]$ such that $\P(\Omega) = 1$ and \[
        \P\ab(\bigsqcup_n A_n) = \sum_n \P(A_n)
    \] for any sequence of pairwise disjoint sets $A_n \in \F$
    (countable additivity).
\end{definition*}
Countable additivity is a stronger condition than finite additivity.
\begin{exercise}
    Prove that countable additivity is equivalent to the following two
    conditions taken together:
    \begin{enumerate}
        \item \textbf{finite additivity:} if $A \cap B = \O$, then
            $\P(A \sqcup B) = \P(A) + \P(B)$
        \item If $A_n \uparrow A$, then $\P(A_n) \uparrow \P(A)$.
    \end{enumerate}
\end{exercise}
\begin{solution}
    We first show that these follow from countable additivity.

    If one takes $A_1 = A$ and $A_n = \O$ for $n \ge 2$, then
    countable additivity implies $\P(\O) = 0$.
    Finite additivity is immediate by taking only $A_3, A_4, \ldots$
    to be empty.

    Let $A_n \uparrow A$.
    Define $B_1 = A_1$ and $B_n = A_n \setminus A_{n-1}$ for $n \ge 2$.
    Then $(B_n)_\N$ are pairwise disjoint and $\bigcup B_n = A$.
    By countable additivity, \[
        \P(A) = \sum_n \P(B_n).
    \] But the partial sums of this series are exactly $\P(A_n)$
    by finite additivity.
    Thus $\P(A) = \lim \P(A_n)$.
\end{solution}

\subsection*{Where do $\Omega$, $\F$, and $\P$ come from?}
$\Omega$ is simply the set of all possible outcomes.

\subsection{The $\sigma$-algebra}
$\F = 2^\Omega$ and $\F = \set{\O, \Omega}$ are bullshit choices.
In reality, $\F$ is always chosen to be the smallest $\sigma$-algebra
containing some specified sets of interest.
That is, for some $\mcS \subseteq 2^\Omega$, $\F = \sigma(\mcS)$.

This is sometimes called the $\sigma$-algebra ``generated by'' \mcS.
However, this can create a misconception.
Recall the similar notion of the \emph{span} of a set of vectors.
We can define the span of a set $S \subseteq V$ of vectors in two ways:
\begin{itemize}
    \item (external) the smallest subspace containing $S$.
    \item (internal) the set of all linear combinations of vectors in $S$.
\end{itemize}
For $\sigma(\mcS)$, there is no ``internal'' definition.
$\sigma(\mcS)$ cannot be generated by unions, intersections, etc. of sets in
\mcS.

A frequent choice for $\mcS$ is the following.
\begin{definition*}[Borel $\sigma$-algebra] \label{def:borel}
    Let $(X, d)$ be a metric space.
    The \emph{Borel $\sigma$-algebra} on $X$ is the smallest
    $\sigma$-algebra containing all open sets in $X$, and is denoted
    $\B(X)$.
\end{definition*}

\subsection{The probability measure}
There is some collection $\mcS \subseteq \Omega$ for which we know what
the probabilities ``should'' be, $\P\colon \mcS \to [0, 1]$.

\begin{question}
    Does $\P$ extend to a probability measure on
    $\sigma(\mcS)$? If so, is it unique?
\end{question}

Uniqueness does not hold.
\begin{example}
    Let $\Omega = \set{1, 2, 3, 4}$ and
    $\mcS = \set{\set{1, 2}, \set{2, 3}, \set{3, 4}}$.
    $\F = \sigma(\mcS) = 2^\Omega$.

    Then the probability measures given by \begin{align*}
        \underline{p} &= (.25, .25, .25, .25) \\
        \underline{q} &= (.5, 0, .5, 0)
    \end{align*} agree on $\mcS$ but differ on $\F$.
\end{example}

When does uniqueness hold?
\subsubsection{Uniqueness}
\begin{definition*}[$\pi$-system] \label{def:pi}
    A collection $\mcS \subseteq 2^\Omega$ is a \emph{$\pi$-system}
    if it is closed under finite intersections.
    That is, for any $A, B \in \mcS$, $A \cap B \in \mcS$.
\end{definition*}
\begin{definition*}[$\lambda$-system] \label{def:lambda}
    A collection $\mcC \subseteq 2^\Omega$ is a \emph{$\lambda$-system}
    if it contains $\Omega$ and is closed under
    \begin{itemize}
        \item proper differences: if $A, B \in \mcC$ and $B \subseteq A$,
            then $A \setminus B \in \mcC$.
        \item increasing limits: if $A_n \in \mcC$ and $A_n \uparrow A$,
            then $A \in \mcC$.
    \end{itemize}
\end{definition*}

\begin{theorem} \label{thm:unique}
    If $\F = \sigma(\mcS)$ where $\mcS$ is a $\pi$-system and
    $P, Q$ are probability measures on $\F$ that agree on $\mcS$,
    then $P = Q$.
\end{theorem}
\begin{proof}[Proof sketch]
    Consider $\mcG = \set{A \in \F \mid P(A) = Q(A)}$.
    Then $\mcG \supseteq \mcS$.
    Further, if $A \in \mcG$, then $A^c \in \mcG$
    since $P(A^c) = 1 - P(A) = 1 - Q(A) = Q(A^c)$.

    If $A, B \in \mcG$ are disjoint, then \[
        P(A \sqcup B) = P(A) + P(B) = Q(A) + Q(B) = Q(A \sqcup B).
    \] But how do we deal with $A, B$ not disjoint?
    We need to show that $A, B \in \mcG \implies A \cap B \in \mcG$.

    \textbf{Resolution:} Show that $\mcG$ is a $\lambda$-system,
    and then apply the \nameref{thm:pi-lambda}.
    Suppose $A, B \in \mcG$ with $B \subseteq A$.
    Then $P(A \setminus B) = P(A) - P(B) = Q(A) - Q(B) = Q(A \setminus B)$.
    Thus $\mcG$ is closed under proper differences.

    If $A_n \uparrow A$ are in $\mcG$, then $P(A_n) \uparrow P(A)$ and
    $Q(A_n) \uparrow Q(A)$.
    But $P(A_n) = Q(A_n)$ for all $n$, so $P(A) = Q(A)$.
    Thus $\mcG$ is closed under increasing limits.

    $\mcG$ contains $\Omega$ since $P(\Omega) = Q(\Omega) = 1$.

    Thus by the $\pi$-$\lambda$ theorem, $\mcG$ is a $\sigma$-algebra
    and thus $\mcG \supseteq \F$.
\end{proof}

\begin{theorem*}[$\pi$-$\lambda$ theorem]
\label{thm:pi-lambda}
    Let $\mcS$ be a $\pi$-system and $\mcC$ be a $\lambda$-system.
    If $\mcC \supseteq \mcS$, then $\mcC \supseteq \sigma(\mcS)$.
\end{theorem*}
This is due to Sierpiński and Dynkin.

What about existence?
\subsubsection{Existence}
In the general case, obviously not.
Consider $\Omega = [0, 1]$ with
\begin{gather*}
    \mcS = \set{(0, \frac12), (0, \frac14), (\frac14, \frac12)} \\
    \P(a, b) = (b - a)^2.
\end{gather*} Then the sum of $\P(0, \frac14)$ and $\P(\frac14, \frac12)$ is
less that $\P(0, \frac12)$.

Let us impose some necessary conditions.
\begin{definition*}[Algebra] \label{def:algebra}
    A collection $\mcA \subseteq 2^\Omega$ is an \emph{algebra}
    if it is closed under complements and finite unions.
\end{definition*}

\begin{theorem*}[Carathéodory's extension theorem] \label{thm:caratheodory}
    Let $\mcS$ be an algebra.
    Assume that $P\colon \mcS \to [0, 1]$ is countably additive.
    Then there exists an extension of $P$ to a probability measure
    $\P$ on $\F = \sigma(\mcS)$.
\end{theorem*}

\begin{corollary}
    The above extension is unique.
\end{corollary}
\begin{proof}
    An algebra is a $\pi$-system.
    \Cref{thm:unique} applies.
\end{proof}

\section{Existence of Lebesgue measure} \label{sec:lebesgue}
\begin{theorem*} \label{thm:lebesgue}
    There is a unique probability measure $\lambda$ on
    $([0, 1], \B_{[0, 1]})$ such that \[
        \lambda([a, b]) = b - a \quad \text{for all } 0 \le a \le b \le 1.
    \]
\end{theorem*}
\begin{proof}
    Let $\Omega = [0, 1)$.

    Let $\mcS_0 = \set{[a, b) \mid 0 \le a \le b \le 1}$.
    Half-open intervals are nice because they are closed under complements:
    $[a, b)^c = [0, a) \sqcup [b, 1)$.

    Let \[
        \mcS = \set{I_1 \sqcup \cdots \sqcup I_k
                \mid k \ge 1, I_j \in \mcS_0}
    \] be the collection of all finite disjoint unions of
    half-open intervals.
    This is an algebra.
\end{proof}
